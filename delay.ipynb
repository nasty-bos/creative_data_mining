{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "import datetime as dt\n",
    "from IPython.display import Audio, display\n",
    "\n",
    "pd.options.mode.chained_assignment = None   # turn off warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import of Delay Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === list one for DD-MM files\n",
    "listpaths1 = [\n",
    "    'https://data.stadt-zuerich.ch/dataset/vbz_fahrzeiten_ogd/resource/152051e6-1193-43c0-89b8-21b361f49970/download/fahrzeiten_soll_ist_20180401_20180407.csv',\n",
    "#     'https://data.stadt-zuerich.ch/dataset/vbz_fahrzeiten_ogd/resource/eb403fd1-8f8b-475e-98aa-f04ee3b255ba/download/fahrzeiten_soll_ist_20180311_20180317.csv']\n",
    "    'https://data.stadt-zuerich.ch/dataset/vbz_fahrzeiten_ogd/resource/97e59d2a-83ec-438f-ae6f-0fe85d9bc1e6/download/fahrzeiten_soll_ist_20180304_20180310.csv',\n",
    "#     'https://data.stadt-zuerich.ch/dataset/vbz_fahrzeiten_ogd/resource/a38c5d0f-b732-4f5a-9786-eb01a2ffa0bb/download/fahrzeiten_soll_ist_20180211_20180217.csv']\n",
    "    'https://data.stadt-zuerich.ch/dataset/vbz_fahrzeiten_ogd/resource/f17a950d-5be5-4b00-bafd-3c859afcc6cc/download/fahrzeiten_soll_ist_20180204_20180210.csv']\n",
    "#     'https://data.stadt-zuerich.ch/dataset/vbz_fahrzeiten_ogd/resource/bf39176c-d6c0-4741-8cd5-4e46e45c608e/download/fahrzeiten_soll_ist_20180107_20180113.csv']\n",
    " \n",
    "frame1 = pd.DataFrame()\n",
    "list_1 = []\n",
    "for path_ in listpaths1:\n",
    "    df1 = pd.read_csv(path_, usecols=[0,1,2,10,11], parse_dates=['betriebsdatum'] ,infer_datetime_format=True,  index_col=None)\n",
    "    list_1.append(df1)\n",
    "df1 = pd.concat(list_1)\n",
    "\n",
    "# === change datime from DD-MM to MM-DD\n",
    "df1['betriebsdatum'] = pd.to_datetime(df1['betriebsdatum'])\n",
    "df1['time'] = df1['betriebsdatum'].dt.strftime('%Y-%d-%m')\n",
    "df1['time'] = pd.to_datetime(df1['time'], format='%Y-%m-%d', errors='ignore')\n",
    "# df1.drop(df1['betriebsdatum'], axis=, inplace=True)\n",
    "\n",
    "# df1['betriebsdatum'] = pd.to_datetime(df1['betriebsdatum'], format='%Y/%m/%d', errors='ignore')\n",
    "# df1['time'] = df1['betriebsdatum'].dt.strftime('%Y/%d/%m')\n",
    "# df1['time'] = pd.to_datetime(df1['time'], format='%Y-%m-%d', errors='ignore')\n",
    "\n",
    "# === list two for MM-DD files\n",
    "listpaths2 = [\n",
    "    'https://data.stadt-zuerich.ch/dataset/vbz_fahrzeiten_ogd/resource/03ec9d0a-b16f-4e78-8e4f-2da4970efbb6/download/fahrzeiten_soll_ist_20180325_20180331.csv',\n",
    "    'https://data.stadt-zuerich.ch/dataset/vbz_fahrzeiten_ogd/resource/c88a3801-c6fc-4d32-8ece-e269899be497/download/fahrzeiten_soll_ist_20180318_20180324.csv',\n",
    "    'https://data.stadt-zuerich.ch/dataset/vbz_fahrzeiten_ogd/resource/a265b5d8-287f-4d22-88b2-f3a1770e1a4a/download/fahrzeiten_soll_ist_20180225_20180303.csv',\n",
    "    'https://data.stadt-zuerich.ch/dataset/vbz_fahrzeiten_ogd/resource/1ac13127-fcde-4ac2-8462-50f348fd28fe/download/fahrzeiten_soll_ist_20180218_20180224.csv',\n",
    "    'https://data.stadt-zuerich.ch/dataset/vbz_fahrzeiten_ogd/resource/ee7f8901-5466-425d-98e6-98ddcf849079/download/fahrzeiten_soll_ist_20180128_20180203.csv',\n",
    "    'https://data.stadt-zuerich.ch/dataset/vbz_fahrzeiten_ogd/resource/b45b383e-4b0d-4ad0-8bee-e958c5e7360a/download/fahrzeiten_soll_ist_20180121_20180127.csv',\n",
    "    'https://data.stadt-zuerich.ch/dataset/vbz_fahrzeiten_ogd/resource/4bbaf516-824a-41b3-8a95-6679745ce7d3/download/fahrzeiten_soll_ist_20180114_20180120.csv',\n",
    "    'https://data.stadt-zuerich.ch/dataset/vbz_fahrzeiten_ogd/resource/b4e64312-e7f6-4b43-a832-1a8e47138732/download/fahrzeiten_soll_ist_20171231_20180106.csv']\n",
    "\n",
    "frame2 = pd.DataFrame()\n",
    "list_2 = []\n",
    "for path_ in listpaths2:\n",
    "    df2 = pd.read_csv(path_, usecols=[0,1,2,10,11], parse_dates=['betriebsdatum'] ,infer_datetime_format=True, index_col=None)\n",
    "    list_2.append(df2)\n",
    "df2 = pd.concat(list_2)\n",
    "\n",
    "df2['time'] = pd.to_datetime(df2['betriebsdatum'])\n",
    "\n",
    "# === put both together\n",
    "frames = [df1, df2]\n",
    "df = pd.concat(frames)\n",
    "\n",
    "# === check status\n",
    "check = pd.DataFrame(data=df)   # check size\n",
    "col = check.shape[1]\n",
    "row = check.shape[0]\n",
    "print('delay data rows: %d' % row)\n",
    "print('delay data columns: %d' % col)\n",
    "print(df.head(3))\n",
    "print(df.dtypes)\n",
    "\n",
    "display(Audio(\"./weather/ape.mp3\", autoplay=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time difference calculation and formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask(df, key, value):\n",
    "    return df[df[key] == value]\n",
    "\n",
    "pd.DataFrame.mask = mask\n",
    "df3 = df.mask('linie', 69)\n",
    "\n",
    "df3.loc[:, 'diff'] = (df3['ist_an_von'] - df3['soll_an_von'])\n",
    "df4 = df3.copy()\n",
    "df4.reset_index(drop=True, inplace=True)\n",
    "df4.loc[:, 'zeit'] = df4.loc[:, 'soll_an_von'].copy().astype(float)\n",
    "df4.loc[:, 'zeit'] = pd.to_datetime(df4.loc[:, 'zeit'], errors='coerce', unit='s')\n",
    "df4.loc[:, 'zeit'] = df4.loc[:, 'zeit'].dt.strftime('%H:%M')\n",
    "df4.loc[:, 'zeit'] = pd.to_datetime(df4.loc[:, 'zeit'], format='%h:%m', errors='ignore')\n",
    "df5 = df4.copy()\n",
    "df5.drop(df5.columns[[3, 4]], axis=1, inplace=True)\n",
    "df6 = df5.copy()\n",
    "df6['time'] = df6['time'].dt.strftime('%Y%m%d')\n",
    "df6['time'] = pd.to_datetime(df6['time'] + ' ' + df5['zeit'])\n",
    "df7 = df6.copy()\n",
    "df7.drop(df7.columns[[2]], axis=1, inplace=True)\n",
    "df7.loc[:, 'diff'] = df7.loc[:, 'diff'].apply(pd.to_numeric, errors='coerce', downcast='float')\n",
    "df7.loc[:, 'time'] = df7.loc[:, 'time'].dt.round('60min')\n",
    "df7 = df7.dropna(how='any')\n",
    "df7['diff'] = df7['diff'].astype(int)\n",
    "df7 = df7.loc[df7['diff'] > 0]\n",
    "df8 = df7.copy()\n",
    "df8.drop(df8.columns[[4]], axis=1, inplace=True)\n",
    "df8['diff'] = df8['diff'] / 60    # from seconds to minutes\n",
    "df8['weekday'] = df8['time'].dt.dayofweek\n",
    "\n",
    "# === check size\n",
    "check = pd.DataFrame(data=df6)\n",
    "col = check.shape[1]\n",
    "row = check.shape[0]\n",
    "print('cleaned diff: %d' % row)\n",
    "print('cleaned diff: %d' % col)\n",
    "print(df4.head())\n",
    "print(df8.head(4))\n",
    "print(df8.dtypes)\n",
    "\n",
    "display(Audio(\"./weather/ape.mp3\", autoplay=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weather Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === input folder\n",
    "path = r'./weather/*.csv'\n",
    "# === import csv as dataframe\n",
    "new_cols = ['weather']\n",
    "we = pd.read_csv('./weather/agrometeo-data.csv', encoding='Latin-1', header=None, names=new_cols)\n",
    "wet1 = pd.DataFrame(data=we)\n",
    "# === clean-up\n",
    "wet = wet1.iloc[3:]\n",
    "wet.loc[:, 'time'] = wet.weather.str.split(';').str.get(0)\n",
    "wet.loc[:, 'temp'] = wet.weather.str.split(';').str.get(1)\n",
    "wet.loc[:, 'rain'] = wet.weather.str.split(';').str.get(2)\n",
    "wet.drop(wet.columns[[0]], axis=1, inplace=True)\n",
    "wet.loc[:, 'time'] = pd.to_datetime(wet.loc[:, 'time'])\n",
    "wet.loc[:, 'rain'] = wet.loc[:, 'rain'].apply(pd.to_numeric, errors='coerce')\n",
    "wet = wet.dropna(how='any')\n",
    "\n",
    "# === check size\n",
    "q = wet.shape[1]\n",
    "o = wet.shape[0]\n",
    "print('weather data rows: %d' % o)\n",
    "print('weather data columns: %d' % q)\n",
    "print(wet.head(3))\n",
    "print(wet.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matching Rain and Time Difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === left merge on both time col which are in datetime format\n",
    "merge = df8.merge(wet, left_on='time', right_on='time', how='left')\n",
    "\n",
    "# === check size                         \n",
    "print(merge.head())\n",
    "print(merge.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Smooth out the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smooth = merge.copy()\n",
    "q = smooth['diff'].quantile(0.99)\n",
    "smooth = smooth[smooth['diff'] <= q]\n",
    "print(q)\n",
    "smooth = smooth.dropna(how='any')\n",
    "style.use('ggplot')\n",
    "scurr = smooth.copy()\n",
    "scurr['hour'] = scurr.loc[:, 'time'].apply(lambda x: x.hour)\n",
    "scurr.drop(scurr.columns[[0, 1]], axis=1, inplace=True)\n",
    "print(scurr.head())\n",
    "# === frequency histogramm\n",
    "plt.hist(smooth.loc[:, 'diff'])\n",
    "plt.title(\"delay frequency\")\n",
    "plt.xlabel(\"delay[minutes]\")\n",
    "plt.ylabel(\"frequency\")\n",
    "plt.savefig('./output/2Dfrequency.png', format='png', dpi=800)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "style.use(\"ggplot\")\n",
    "\n",
    "# === output folder\n",
    "newpath = r'./output/'\n",
    "if os.path.exists(newpath):\n",
    "    shutil.rmtree(newpath, ignore_errors=True)\n",
    "os.makedirs(newpath)\n",
    "\n",
    "month = smooth.copy()\n",
    "day = smooth.copy()\n",
    "hour = smooth.copy()\n",
    "\n",
    "month['time'] = month.loc[:, 'time'].apply(lambda x: x.month)\n",
    "day['time'] = day.loc[:, 'time'].apply(lambda x: x.day)\n",
    "hour['time'] = hour.loc[:, 'time'].apply(lambda x: x.hour)\n",
    "\n",
    "# === csv to check output data\n",
    "# merge.to_csv('./output/merge.csv', header=False, index=False)\n",
    "# wet.to_csv('./output/wet.csv', header=False, index=False)\n",
    "# df1.to_csv('./output/df1.csv', header=False, index=False)\n",
    "\n",
    "# === 2D monthly distribution of delays\n",
    "x = month.loc[:, 'time']\n",
    "y = month.loc[:, 'diff']\n",
    "plt.scatter(x, y)\n",
    "plt.title(\"monthly distribution\")\n",
    "plt.xlabel(\"months\")\n",
    "plt.ylabel(\"delay[minutes]\")\n",
    "plt.savefig('./output/2Dmonthly.png', format='png', dpi=800)\n",
    "# plt.show()\n",
    "\n",
    "# === 2D daily distribution of delays\n",
    "x = day.loc[:, 'weekday']\n",
    "y = day.loc[:, 'diff']\n",
    "plt.scatter(x, y)\n",
    "plt.title(\"daily distribution\")\n",
    "plt.xlabel(\"weekday\")\n",
    "plt.ylabel(\"delay[minutes]\")\n",
    "plt.savefig('./output/2Ddaily.png', format='png', dpi=800)\n",
    "# plt.show()\n",
    "\n",
    "# === 2D hourly distribution of delays\n",
    "x = hour.loc[:, 'time']\n",
    "y = hour.loc[:, 'diff']\n",
    "plt.scatter(x, y)\n",
    "plt.title(\"hourly distribution\")\n",
    "plt.xlabel(\"hours\")\n",
    "plt.ylabel(\"delay[minutes]\")\n",
    "plt.savefig('./output/2Dhourly.png', format='png', dpi=800)\n",
    "# plt.show()\n",
    "\n",
    "# === 2D dependency on rain\n",
    "x = smooth.loc[:, 'rain']\n",
    "y = smooth.loc[:, 'diff']\n",
    "plt.scatter(x, y)\n",
    "plt.title(\"correlation\")\n",
    "plt.xlabel(\"rain[mm/m2]\")\n",
    "plt.ylabel(\"delay[minutes]\")\n",
    "plt.savefig('./output/2Drain-delay.png', format='png', dpi=800)\n",
    "# plt.show()\n",
    "\n",
    "# === 3D Figure rain, time, delay\n",
    "x = hour.loc[:, 'time']\n",
    "y = hour.loc[:, 'rain']\n",
    "z = hour.loc[:, 'diff']\n",
    "fig = plt.figure()\n",
    "ax = Axes3D(fig)\n",
    "ax.scatter(x, y, z)\n",
    "plt.title(\"Correlation\")\n",
    "ax.set_xlabel('hours')\n",
    "ax.set_ylabel('rain [mm/m2]')\n",
    "ax.set_zlabel('delay[minutes]')\n",
    "plt.savefig('./output/3DcorrelationHourly.png', format='png', dpi=800)\n",
    "# plt.show()\n",
    "\n",
    "# === other statistics on data\n",
    "\n",
    "print(smooth.loc[:,'rain'].describe())\n",
    "print(smooth.loc[:,'diff'].describe())\n",
    "\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(smooth.loc[:, 'rain'], smooth.loc[:, 'diff'])\n",
    "print(\"r-squared value between rain and delay:\", r_value ** 2)\n",
    "\n",
    "display(Audio(\"./weather/ape.mp3\", autoplay=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import cross_validation, linear_model\n",
    "import pickle\n",
    "\n",
    "dataframe = scurr\n",
    "array = dataframe.values\n",
    "X = array[:,[2,3,4,5]]\n",
    "Y = array[:,[1]].ravel()\n",
    "Y = Y.astype('int')\n",
    "test_size = 0.33\n",
    "seed = 2\n",
    "X_train, X_test, Y_train, Y_test = model_selection.train_test_split(X, Y, test_size=test_size, random_state=seed)\n",
    "\n",
    "plt.scatter(X[:, 0], X[:, 2])\n",
    "plt.xlabel('weekday')\n",
    "plt.ylabel('precipitation[mm/m2]')\n",
    "plt.title('precipitation & weekday')\n",
    "plt.savefig('./output/weekdays&rain.png', format='png', dpi=800)\n",
    "plt.show()\n",
    "\n",
    "loo = cross_validation.LeaveOneOut(len(Y))\n",
    "# its going down\n",
    "model = SVC(kernel = 'linear', C = 1.0, decision_function_shape='ovo')\n",
    "# model = LogisticRegression()\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "# save the model to disk\n",
    "filename = 'first_prediction.sav'\n",
    "pickle.dump(model, open(filename, 'wb'))\n",
    "\n",
    "scores = cross_validation.cross_val_score(model, X_digits, Y_digits, scoring='neg_mean_squared_error', cv=loo,)\n",
    "print('Mean score from cross validation:', scores.mean())\n",
    "# print('CrossValScore:', cross_val_score(model, X_train, Y_train, scoring='neg_mean_squared_error'))\n",
    "\n",
    "# # load the model from disk\n",
    "# loaded_model = pickle.load(open(filename, 'rb'))\n",
    "# result = loaded_model.score(X_test, Y_test)\n",
    "# print(result)\n",
    "\n",
    "pred = model.predict(X_test)\n",
    "\n",
    "for i in range(5):\n",
    "    print(\"X=%s, Predicted=%s\" % (X_test[i], Y_test[i]))\n",
    "\n",
    "display(Audio(\"./weather/ape.mp3\", autoplay=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
