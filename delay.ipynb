{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import pickle\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "from IPython.display import Audio, display\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import model_selection\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from pandas.plotting import autocorrelation_plot\n",
    "pd.options.mode.chained_assignment = None   # turn off warnings\n",
    "\n",
    "style.use('ggplot')\n",
    "\n",
    "# === check size \n",
    "def checksize(dataframe):\n",
    "    q = dataframe.shape[1]\n",
    "    o = dataframe.shape[0]\n",
    "    print('data rows: %d' % o)\n",
    "    print('data columns: %d' % q)\n",
    "    print(dataframe.head(2))\n",
    "    print(dataframe.dtypes)\n",
    "    \n",
    "# === output folder\n",
    "newpath = r'./output/'\n",
    "if os.path.exists(newpath):\n",
    "    shutil.rmtree(newpath, ignore_errors=True)\n",
    "os.makedirs(newpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get delay data from .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df69 = pd.read_csv(r'./delay_data/df_69.csv')\n",
    "df = pd.read_csv(r'./delay_data/df.csv')\n",
    "\n",
    "# df69['time'] = pd.to_datetime(df69['time'])\n",
    "df['time'] = pd.to_datetime(df['time'])\n",
    "\n",
    "# checksize(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get weather data from .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === input folder\n",
    "path = r'./weather/*.csv'\n",
    "# === import csv as dataframe\n",
    "new_cols = ['weather']\n",
    "we = pd.read_csv('./weather/agrometeo-data.csv', encoding='Latin-1', header=None, names=new_cols)\n",
    "wet1 = pd.DataFrame(data=we)\n",
    "# === clean-up\n",
    "wet = wet1.iloc[3:]\n",
    "wet.loc[:, 'time'] = wet.weather.str.split(';').str.get(0)\n",
    "wet.loc[:, 'temp'] = wet.weather.str.split(';').str.get(1)\n",
    "wet.loc[:, 'rain'] = wet.weather.str.split(';').str.get(2)\n",
    "wet.drop(wet.columns[[0]], axis=1, inplace=True)\n",
    "wet.loc[:, 'time'] = pd.to_datetime(wet.loc[:, 'time'])\n",
    "wet.loc[:, 'rain'] = wet.loc[:, 'rain'].apply(pd.to_numeric, errors='coerce')\n",
    "wet['temp'] = wet['temp'].astype(float)\n",
    "wet = wet.dropna(how='any')\n",
    "\n",
    "# === 2D temp and rain\n",
    "x = wet['temp']\n",
    "y = wet['rain']\n",
    "plt.scatter(x, y)\n",
    "plt.title(\"\")\n",
    "plt.xlabel(\"temp[C]\")\n",
    "plt.ylabel(\"precipitation[mm/m2]\")\n",
    "plt.savefig('./output/raintemp.png', format='png', dpi=800)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## merge delay and weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === inner merge on both time col which are in datetime format\n",
    "# === choose between df and df69!!!\n",
    "merge = df.merge(wet, left_on='time', right_on='time', how='inner')\n",
    "\n",
    "checksize(merge)\n",
    "\n",
    "# # === 2D temp and rain\n",
    "# x = merge['rain']\n",
    "# y = merge['diff']\n",
    "# plt.scatter(x, y)\n",
    "# plt.title(\"\")\n",
    "# plt.xlabel(\"precipitation[mm/m2]\")\n",
    "# plt.ylabel(\"delay[min]\")\n",
    "# plt.savefig('./output/raintemp.png', format='png', dpi=800)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## smooth out data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smooth = merge.copy()\n",
    "# smooth = smooth.set_index('time')\n",
    "diffmean = smooth.groupby('time').diff.mean().to_frame()\n",
    "rainmean = smooth.groupby('time').rain.mean().to_frame()\n",
    "weekday = smooth.groupby('time').weekday.mean().to_frame()\n",
    "hour = smooth.groupby('time').hour.mean().to_frame()\n",
    "tempmean = smooth.groupby('time').temp.mean().to_frame()\n",
    "\n",
    "smooth = diffmean.merge(rainmean, left_index=True, right_index=True, how='left')\n",
    "smooth = smooth.merge(weekday, left_index=True, right_index=True, how='left')\n",
    "smooth = smooth.merge(hour, left_index=True, right_index=True, how='left')\n",
    "smooth = smooth.merge(tempmean, left_index=True, right_index=True, how='left')\n",
    "smooth = smooth.reset_index()\n",
    "\n",
    "\n",
    "# === Changes in dataset\n",
    "# smooth = smooth[smooth['diff'] > 0]    # only positive delays\n",
    "# smooth = smooth[smooth['temp'] > 0]\n",
    "# smooth['diff'] = smooth['diff']*60    # seconds delay\n",
    "# smooth = smooth[smooth['diff'] > 120]    # focus on extreme delays\n",
    "# smooth['diff'] = smooth['diff'].astype('int')\n",
    "# smooth['temp'] = smooth['temp'].astype('int')\n",
    "# smooth['rain'] = smooth['rain']*10     # from mm/m2 to (mm/m2)/10\n",
    "# smooth['rain'] = smooth['rain'].astype('int')\n",
    "\n",
    "q = smooth['diff'].quantile(0.99)\n",
    "print(q)\n",
    "smooth = smooth[smooth['diff'] <= q]\n",
    "smooth = smooth[smooth['diff'] >= -q]\n",
    "smooth = smooth.dropna(how='any')\n",
    "\n",
    "smooth['temp'] = smooth['temp'].round(decimals=2)\n",
    "smooth['rain'] = smooth['rain'].round(decimals=2)\n",
    "\n",
    "dataframe = smooth\n",
    "array = dataframe.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weekday polynomial representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('[time(0), diff(1), rain(2), weekday(3), hour(4), temp(5)]')\n",
    "X = array[:,[3]]\n",
    "y = X**4 + X**3 + X + 1\n",
    "\n",
    "x_train, x_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "rmses = []\n",
    "degrees = np.arange(1, 10)\n",
    "min_rmse, min_deg = 1e10, 0\n",
    "\n",
    "for deg in degrees:\n",
    "\n",
    "    # Train features\n",
    "    poly_features = PolynomialFeatures(degree=deg, include_bias=False)\n",
    "    x_poly_train = poly_features.fit_transform(x_train)\n",
    "\n",
    "    # Linear regression\n",
    "    poly_reg = LinearRegression()\n",
    "    poly_reg.fit(x_poly_train, y_train)\n",
    "\n",
    "    # Compare with test data\n",
    "    x_poly_test = poly_features.fit_transform(x_test)\n",
    "    poly_predict = poly_reg.predict(x_poly_test)\n",
    "    poly_mse = mean_squared_error(y_test, poly_predict)\n",
    "    poly_rmse = np.sqrt(poly_mse)\n",
    "    rmses.append(poly_rmse)\n",
    "\n",
    "    # Cross-validation of degree\n",
    "    if min_rmse > poly_rmse:\n",
    "        min_rmse = poly_rmse\n",
    "        min_deg = deg\n",
    "\n",
    "# Plot and present results\n",
    "print('Best degree {} with RMSE {}'.format(min_deg, min_rmse))\n",
    "\n",
    "x = smooth['weekday']\n",
    "y = smooth['diff']\n",
    "\n",
    "z = np.polyfit(x, y, min_deg)\n",
    "p = np.poly1d(z)\n",
    "\n",
    "xp = np.linspace(0, 6, 100)\n",
    "_ = plt.plot(x, y, '.', xp, p(xp), '-')\n",
    "plt.title(\"Weekday\")\n",
    "plt.xlabel(\"weekday\")\n",
    "plt.ylabel(\"delay[minutes]\")\n",
    "plt.savefig('./output/weekday_poly.png', format='png', dpi=1200)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# plt.plot(smooth['weekday'], smooth['diff'], '.')\n",
    "# plt.plot(smooth['weekday'], slope*smooth['weekday'] + intercept, '-')\n",
    "# plt.xlabel(\"weekday\")\n",
    "# plt.ylabel(\"delay[seconds]\")\n",
    "# plt.savefig('./output/weekday_delayLinReg.png', format='png', dpi=800)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## hour polynomial representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('[time(0), diff(1), rain(2), weekday(3), hour(4), temp(5)]')\n",
    "\n",
    "X = array[:,[4]]\n",
    "y = X**4 + X**3 + X + 1\n",
    "\n",
    "x_train, x_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "rmses = []\n",
    "degrees = np.arange(1, 30)\n",
    "min_rmse, min_deg = 1e10, 0\n",
    "\n",
    "for deg in degrees:\n",
    "\n",
    "    # Train features\n",
    "    poly_features = PolynomialFeatures(degree=deg, include_bias=False)\n",
    "    x_poly_train = poly_features.fit_transform(x_train)\n",
    "\n",
    "    # Linear regression\n",
    "    poly_reg = LinearRegression()\n",
    "    poly_reg.fit(x_poly_train, y_train)\n",
    "\n",
    "    # Compare with test data\n",
    "    x_poly_test = poly_features.fit_transform(x_test)\n",
    "    poly_predict = poly_reg.predict(x_poly_test)\n",
    "    poly_mse = mean_squared_error(y_test, poly_predict)\n",
    "    poly_rmse = np.sqrt(poly_mse)\n",
    "    rmses.append(poly_rmse)\n",
    "\n",
    "    # Cross-validation of degree\n",
    "    if min_rmse > poly_rmse:\n",
    "        min_rmse = poly_rmse\n",
    "        min_deg = deg\n",
    "\n",
    "# Plot and present results\n",
    "print('Best degree {} with RMSE {}'.format(min_deg, min_rmse))\n",
    "\n",
    "x = smooth['hour']\n",
    "y = smooth['diff']\n",
    "\n",
    "z = np.polyfit(x, y, min_deg)\n",
    "p = np.poly1d(z)\n",
    "\n",
    "xp = np.linspace(0, 23, 100)\n",
    "_ = plt.plot(x, y, '.', xp, p(xp), '-')\n",
    "plt.title(\"Hour of Day\")\n",
    "plt.xlabel(\"hour of day\")\n",
    "plt.ylabel(\"delay[minutes]\")\n",
    "plt.savefig('./output/hour_poly.png', format='png', dpi=1200)\n",
    "plt.show()\n",
    "\n",
    "autocorrelation_plot([x, y])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear regressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === temp\n",
    "print('correlation temp-delay: ', np.corrcoef(smooth.loc[:, 'temp'], smooth.loc[:, 'diff']))\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(smooth.loc[:, 'temp'], smooth.loc[:, 'diff'])\n",
    "print(\"r-squared value between temperature and delay:\", r_value ** 2)\n",
    "\n",
    "plt.plot(smooth['temp'], smooth['diff'], '.')\n",
    "plt.plot(smooth['temp'], slope*smooth['temp'] + intercept, '-')\n",
    "plt.title(\"Temperature\")\n",
    "plt.xlabel(\"temp[C]\")\n",
    "plt.ylabel(\"delay[minutes]\")\n",
    "plt.savefig('./output/temp_lin.png', format='png', dpi=1200)\n",
    "plt.show()\n",
    "\n",
    "scurr = smooth[smooth['rain'] > 0]    # only rainevents\n",
    "# === rain\n",
    "print('correlation rain-delay: ', np.corrcoef(scurr['rain'], scurr['diff']))\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(scurr.loc[:, 'rain'], scurr.loc[:, 'diff'])\n",
    "print('slope, intercept, r_value, p_value, std_err :', slope, intercept, r_value, p_value, std_err)\n",
    "print(\"r-squared value between rain and delay:\", r_value ** 2)\n",
    "plt.plot(scurr['rain'], scurr['diff'], '.')\n",
    "plt.plot(scurr['rain'], slope*scurr['rain'] + intercept, '-')\n",
    "plt.title(\"Rain\")\n",
    "plt.xlabel(\"rain[mm/h]\")\n",
    "plt.ylabel(\"delay[minutes]\")\n",
    "plt.savefig('./output/rain_lin.png', format='png', dpi=1200)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# x1 = X_train[:,1].astype(int)\n",
    "# x2 = X_test[:,1].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('[time(0), diff(1), rain(2), weekday(3), hour(4), temp(5)]')\n",
    "\n",
    "scurr['diff'] = scurr['diff']*60    # seconds delay\n",
    "dataframe = scurr\n",
    "array = dataframe.values\n",
    "\n",
    "X = array[:,[2,3,4,5]]\n",
    "Y = array[:,[1]].astype('int')\n",
    "Y = Y.ravel()\n",
    "\n",
    "test_size = 0.33\n",
    "seed = 42\n",
    "X_train, X_test, Y_train, Y_test = model_selection.train_test_split(X, Y, test_size=test_size, random_state=seed)\n",
    "\n",
    "# sorted_index = np.argsort(X_test)\n",
    "# X_test = X_test[sorted_index]\n",
    "# Y_test = Y_test[sorted_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automatic Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('features: rain(0), weekday(1), hour(2), temp(3)')\n",
    "# # === chi2 feature extraction  # not possible with negative values\n",
    "# test = SelectKBest(score_func=chi2, k=4)\n",
    "# fit = test.fit(X_train, Y_train)\n",
    "# # summarize scores\n",
    "# np.set_printoptions(precision=3)\n",
    "# print('chi2 scores: ', fit.scores_)\n",
    "# features = fit.transform(X)\n",
    "# # summarize selected features\n",
    "# print('chi2 features: ',features[0:5,:])\n",
    "\n",
    "# === ExtraTreesClassifier feature extraction\n",
    "model = ExtraTreesClassifier()\n",
    "model.fit(X, Y)\n",
    "print('ExtraTreesClassifier feature importance: ', model.feature_importances_)\n",
    "\n",
    "# === PCA\n",
    "features = ['rain','weekday', 'hour', 'temp']\n",
    "# Separating out the features\n",
    "x = smooth.loc[:, features].values\n",
    "# Separating out the target\n",
    "y = smooth.loc[:,['diff']].values\n",
    "# Standardizing the features\n",
    "x = StandardScaler().fit_transform(x)\n",
    "\n",
    "# feature extraction\n",
    "pca = PCA(n_components=2)\n",
    "fit = pca.fit(x)\n",
    "# summarize components\n",
    "print(\"Explained Variance: \", fit.explained_variance_ratio_)\n",
    "print('PCA components: ', fit.components_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('[time(0), diff(1), rain(2), weekday(3), hour(4), temp(5)]')\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "series = array[:,[0,1]]\n",
    "series[:,0] = smooth['time'].dt.strptime('190'+x, '%Y-%m-%d %h')\n",
    "# series[:,0] = np.array(series[:,0], dtype='datetime64[h]')\n",
    "series[:,1] = np.array(series[:,1], dtype='int')\n",
    "\n",
    "print(series)\n",
    "# print(series.dtypes)\n",
    "# fit model\n",
    "model = ARIMA(series, order=(5,1,0))\n",
    "model_fit = model.fit(disp=0)\n",
    "print(model_fit.summary())\n",
    "# plot residual errors\n",
    "residuals = pd.DataFrame(model_fit.resid)\n",
    "residuals.plot()\n",
    "plt.show()\n",
    "residuals.plot(kind='kde')\n",
    "plt.show()\n",
    "print(residuals.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selected Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('[time(0), diff(1), rain(2), weekday(3), hour(4), temp(5)]')\n",
    "\n",
    "dataframe = scurr\n",
    "array = dataframe.values\n",
    "X = array[:,[2,3,4,5]]\n",
    "Y = array[:,[1]].astype('int')\n",
    "Y = Y.ravel()\n",
    "\n",
    "test_size = 0.33\n",
    "seed = 42\n",
    "X_train, X_test, Y_train, Y_test = model_selection.train_test_split(X, Y, test_size=test_size, random_state=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X, Y)\n",
    "\n",
    "scores = cross_val_score(model, X, Y, scoring='neg_mean_squared_error')\n",
    "print('neg_mean_squared_error: ', scores.mean())\n",
    "\n",
    "# # save the model to disk\n",
    "# filename = 'first_prediction.sav'\n",
    "# pickle.dump(model, open(filename, 'wb'))\n",
    "\n",
    "# # load the model from disk\n",
    "# loaded_model = pickle.load(open(filename, 'rb'))\n",
    "# result = loaded_model.score(X_test, Y_test)\n",
    "# print(result)\n",
    "\n",
    "pred = model.predict(X_test)\n",
    "print('features: [rain, weekday, hour, temp]')\n",
    "for i in range(10):\n",
    "    print(\"X=%s, Predicted=%s\" % (X_test[i] , Y_test[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "clf = MLPClassifier(solver='adam', alpha=1e-5, hidden_layer_sizes=(10, 2), random_state=1,\n",
    "                    max_iter=300, shuffle=True, momentum=0.8, epsilon=1e-08, verbose=True, early_stopping=True)\n",
    "clf.fit(X_train, Y_train)\n",
    "\n",
    "scores = cross_val_score(model, X_train, Y_train, scoring='neg_mean_squared_error')\n",
    "print('neg_mean_squared_error:', scores.mean())\n",
    "\n",
    "pred = model.predict(X_test)\n",
    "print('[weekday, hour]')\n",
    "for i in range(10):\n",
    "    print(\"X=%s, Predicted=%s\" % (X_test[i], Y_test[i]))\n",
    "\n",
    "display(Audio(\"./weather/ape.mp3\", autoplay=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## visualize, analyse data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "style.use(\"ggplot\")\n",
    "\n",
    "# show input features\n",
    "plt.scatter(X[:, 0], X[:, 3], s=40, c=Y, cmap=plt.cm.Spectral)\n",
    "plt.xlabel('weekday')\n",
    "plt.ylabel('precipitation[mm*10/m2]')\n",
    "plt.title('precipitation & weekday')\n",
    "plt.savefig('./output/weekdays&rain.png', format='png', dpi=800)\n",
    "plt.show()\n",
    "\n",
    "month = scurr.copy()\n",
    "day = scurr.copy()\n",
    "hour = smooth.copy()\n",
    "\n",
    "month['time'] = month.loc[:, 'time'].apply(lambda x: x.month)\n",
    "day['time'] = day.loc[:, 'time'].apply(lambda x: x.day)\n",
    "hour['time'] = hour.loc[:, 'time'].apply(lambda x: x.hour)\n",
    "\n",
    "# # === 2D monthly distribution of delays\n",
    "# x = month.loc[:, 'time']\n",
    "# y = month.loc[:, 'diff']\n",
    "# plt.scatter(x, y)\n",
    "# plt.title(\"monthly distribution\")\n",
    "# plt.xlabel(\"months\")\n",
    "# plt.ylabel(\"delay[minutes]\")\n",
    "# plt.savefig('./output/2Dmonthly.png', format='png', dpi=800)\n",
    "# # plt.show()\n",
    "\n",
    "# # === 2D daily distribution of delays\n",
    "# x = day.loc[:, 'weekday']\n",
    "# y = day.loc[:, 'diff']\n",
    "# plt.scatter(x, y)\n",
    "# plt.title(\"daily distribution\")\n",
    "# plt.xlabel(\"weekday\")\n",
    "# plt.ylabel(\"delay[minutes]\")\n",
    "# plt.savefig('./output/2Ddaily.png', format='png', dpi=800)\n",
    "# # plt.show()\n",
    "\n",
    "# # === 2D hourly distribution of delays\n",
    "# x = hour.loc[:, 'time']\n",
    "# y = hour.loc[:, 'diff']\n",
    "# plt.scatter(x, y)\n",
    "# plt.title(\"hourly distribution\")\n",
    "# plt.xlabel(\"hours\")\n",
    "# plt.ylabel(\"delay[minutes]\")\n",
    "# plt.savefig('./output/2Dhourly.png', format='png', dpi=800)\n",
    "# # plt.show()\n",
    "\n",
    "# # === 2D dependency on rain\n",
    "# x = smooth.loc[:, 'rain']\n",
    "# y = smooth.loc[:, 'diff']\n",
    "# plt.scatter(x, y)\n",
    "# plt.title(\"correlation\")\n",
    "# plt.xlabel(\"rain[mm/m2]\")\n",
    "# plt.ylabel(\"delay[minutes]\")\n",
    "# plt.savefig('./output/2Drain-delay.png', format='png', dpi=800)\n",
    "# # plt.show()\n",
    "\n",
    "# === 3D Figure rain, time, delay\n",
    "x = hour.loc[:, 'time']\n",
    "y = hour.loc[:, 'rain']\n",
    "z = hour.loc[:, 'diff']\n",
    "fig = plt.figure()\n",
    "ax = Axes3D(fig)\n",
    "ax.scatter(x, y, z)\n",
    "plt.title(\"Correlation\")\n",
    "ax.set_xlabel('hours')\n",
    "ax.set_ylabel('rain [mm/m2]')\n",
    "ax.set_zlabel('delay[minutes]')\n",
    "plt.savefig('./output/3DcorrelationHourly.png', format='png', dpi=800)\n",
    "# plt.show()\n",
    "\n",
    "# === other statistics on data\n",
    "\n",
    "print(smooth.loc[:,'rain'].describe())\n",
    "print(smooth.loc[:,'diff'].describe())\n",
    "\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(smooth.loc[:, 'rain'], smooth.loc[:, 'diff'])\n",
    "print(\"r-squared value between rain and delay:\", r_value ** 2)\n",
    "\n",
    "display(Audio(\"./weather/ape.mp3\", autoplay=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
